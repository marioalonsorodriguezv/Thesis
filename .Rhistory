par(mar = c(4, 5, 2, 1))  # Sets plot margins
barplot(feeds[order(feeds)],
horiz  = TRUE,
las    = 1,  # las gives orientation of axis labels
col    = c("beige", "blanchedalmond", "bisque1", "bisque2", "bisque3", "bisque4"),
border = NA,  # No borders on bars
main   = "Frequencies of Different Feeds\nin chickwts Dataset",  # \n = line break
xlab   = "Number of Chicks")
?par
# LOAD DATASETS PACKAGE
require("datasets")
# ONE ROW PER CASE
data(chickwts)
# LOAD DATASETS PACKAGE
require("datasets")
# ONE ROW PER CASE
data(chickwts)
# Create a table with frequencies
feeds <- table(chickwts$feed)
feeds
# LOAD DATASETS PACKAGE
require("datasets")
# ONE ROW PER CASE
data(chickwts)
# Create a table with frequencies
feeds <- table(chickwts$feed)
feeds
# Make the pie chart with the defaults
pie(feeds)
?pie
# Modify the pie chart
pie(feeds[order(feeds, decreasing = TRUE)],
init.angle = 90,   # Starts as 12 o'clock instead of 3
clockwise = TRUE,  # Default is FALSE
col = c("seashell", "cadetblue2", "lightpink", "lightcyan", "plum1", "papayawhip"),
main = "Pie Chart of Feeds from chickwts")
pie.a <- c(22, 14, 18, 20, 14, 12)
pie.b <- c(20, 18, 16, 18, 16, 12)
pie.c <- c(12, 14, 20, 18, 14, 22)
oldpar <- par()   # Stores old graphical parameters
par(mfrow    = c(1, 3),  # Num. rows/cols
cex.main = 3)   #  Main title 3x bigger
colors <- c("grey98", "grey90", "lightskyblue", "lightgreen", "grey98", "grey90")
?colors
# Three pie charts side by side
# Is the green slice or blue slice bigger?
pie(pie.a, main = "Pie A", col = colors)
pie(pie.b, main = "Pie B", col = colors)
pie(pie.c, main = "Pie C", col = colors)
barplot(pie.a, main = "Bar A", col = colors)
barplot(pie.b, main = "Bar B", col = colors)
barplot(pie.c, main = "Bar C", col = colors)
par(oldpar)  # Restore old graphical parameters
# Note that cin, cra, csi, cxy, and din are read-only
# parameters that were written to oldpar but cannot be
# rewritten; just ignore the warning messages for these.
?par
rm(list = lm())  # Clean up
rm(list = lm())  # Clean up
# LOAD DATASETS PACKAGE
require("datasets")
?lynx
data(lynx)  # Annual Canadian Lynx trappings 1821-1934
# Make a histogram using the defaults
hist(lynx)
?hist
h <- hist(lynx,  # Save histogram as object
breaks = 11,  # "Suggests" 11 bins
#           breaks = seq(0, 7000, by = 100),
#           breaks = c(0, 100, 300, 500, 3000, 3500, 7000),
freq = FALSE,
col = "thistle1", # Or use: col = colors() [626]
main = "Histogram of Annual Canadian Lynx Trappings\n1821-1934",
xlab = "Number of Lynx Trapped")
# IF freq = FALSE, this will draw normal distribution
curve(dnorm(x, mean = mean(lynx), sd = sd(lynx)),
col = "thistle4",
lwd = 2,
add = TRUE)
?curve
rm(list = ls())  # Clean up
# LOAD DATASET
require("datasets")
# Lawyers' Ratings of State Judges in the US Superior Court (c. 1977)
?USJudgeRatings
USJudgeRatings  # View data
data(USJudgeRatings)  # Load into workspace
# At least two errors in data file:
# 1. Data appears to be on 1-10 or 0-10 scale but Callahan
#    has a 10.6 on CONT. 8.6 seems more likely.
# 2. Santaniello's last name is misspelled
# Best to fix errors in spreadsheet and reimport
#################################
#################################
#################################
# R Statistics Essential Training
# Ex02_05
# Overlaying Plots
# LOAD DATASET
require("datasets")
?swiss
swiss
str(swiss)
data(swiss)
fertility <- swiss$Fertility
h <- hist(fertility,
prob = TRUE,  # Flipside of "freq = FALSE"
ylim = c(0, 0.04),
xlim = c(30, 100),
breaks = 11,
col = "#E5E5E5",
border = 0,
main = "Fertility for 47 French-Speaking\nSwiss Provinces, c. 1888")
curve(dnorm(x, mean = mean(fertility), sd = sd(fertility)),
col = "red",
lwd = 3,
add = TRUE)
lines(density(fertility), col = "blue")
lines(density(fertility, adjust = 3), col = "darkgreen")
rug(fertility, col = "red")
rm(list = ls())  # Clean up
# Load data
require("datasets")
feeds <- table(chickwts$feed)
png(filename= "~/Desktop/R/Ex02_06a.png",  # Open device
width = 888,
height = 571)
par(oma = c(1, 1, 1, 1))  # Outside margins: b, l, t, r
par(mar = c(4, 5, 2, 1))  # Sets plot margins
barplot(feeds[order(feeds)],  # Create the chart
horiz  = TRUE,
las    = 1,  # Orientation of axis labels
col    = c("beige", "blanchedalmond", "bisque1", "bisque2", "bisque3", "bisque4"),
border = NA,  # No borders on bars
main   = "Frequencies of Different Feeds\nin chickwts Dataset",
xlab   = "Number of Chicks")
dev.off()  # Close device (run in same block)
pdf("~/Desktop/R/Ex02_06b.pdf",
width = 9,
height = 6)
par(oma = c(1, 1, 1, 1))  # Outside margins: b, l, t, r
par(mar = c(4, 5, 2, 1))  # Sets plot margins
barplot(feeds[order(feeds)],  # Create the chart
horiz  = TRUE,
las    = 1,  # Orientation of axis labels
col    = c("beige", "blanchedalmond", "bisque1", "bisque2", "bisque3", "bisque4"),
border = NA,  # No borders on bars
main   = "Frequencies of Different Feeds\nin chickwts Dataset",
xlab   = "Number of Chicks")
dev.off()  # Close device (run in same block)
par(oma = c(1, 1, 1, 1))  # Outside margins: b, l, t, r
par(mar = c(4, 5, 2, 1))  # Sets plot margins
barplot(feeds[order(feeds)],  # Create the chart
horiz  = TRUE,
las    = 1,  # Orientation of axis labels
col    = c("beige", "blanchedalmond", "bisque1", "bisque2", "bisque3", "bisque4"),
border = NA,  # No borders on bars
main   = "Frequencies of Different Feeds\nin chickwts Dataset",
xlab   = "Number of Chicks")
# Load data
pl <- iris$Petal.Length
hist(pl,
prob = TRUE,
breaks = 12,
col = "#E5E5E5",
border = 0,
main = "Petal Lengths from Three Species of Iris")
# Plot 2: Kernel density lines
lines(density(pl), col = "darkred", lwd = 2)
# Plot 3: Rug
rug(pl, col = "darkgray", lwd = 2)
# LOAD DATASET
require("datasets")
?cars
cars
str(cars)
data(cars)
summary(cars$speed)  # Summary for one variable
summary(cars)  # Summary for entire table
help(package = "psych")
install.packages("psych")
require("psych")
describe(cars)
install.packages("psych")
# Load data
?quakes
quakes[1:5, ]  # See the first 5 lines of the data
mag <- quakes$mag  # Just load the magnitude variable
mag[1:5]  # First 5 lines
# Use t-test for one-sample
# Default t-test (compares mean to 0)
t.test(mag)
# One-sided t-test w/mu = 4
t.test(mag, alternative = "greater", mu = 4)
# LOAD DATASET
require("datasets")
?swiss
swiss
str(swiss)
data(swiss)
fertility <- swiss$Fertility
# Load Data
data(mtcars)
summary(mtcars)
# Use the package "psych"
require("psych")
d <- describe(mtcars[c(1, 4, 7)]) # variables 1, 4 & 7.
View(d)
a <- mtcars[c(1, 4, 7)]
View(a)
#################################
#################################
#################################
# R Statistics Essential Training
# Ex04_01
# Examining outliers
# Categorical data
# Outlier is < 10%
# Worldwide shipments of smartphone OS
# in millions for 2013 Q1
OS <- read.csv("~/Desktop/R/OS.csv", header = TRUE)
View(OS)
OS
# Categorical data
# Outlier is < 10%
# Worldwide shipments of smartphone OS
# in millions for 2013 Q1
OS <- read.csv("/Users/alvarolopezguiresse/GoogleDrive/[] ADMINISTRACION PUBLICA/[4] STATS/R/Exercise Files/Ch04/04_01", header = TRUE)
View(OS)
OS
OS <- read.csv("~/Desktop/R/OS.csv", header = TRUE)
View(OS)
OS
View(OS)
# Outlier has proportion < .10
# Either combine into "other" (if homogeneous) or delete
OS.hi <- subset(OS, Proportion > 0.1)
OS.hi
rm(list = ls())  # Clean up
# Quantitative data
# See outliers in boxplots
require("datasets")
?rivers
data(rivers)  # Lengths of Major North American Rivers
hist(rivers)
rivers
summary(rivers)
hist(rivers)
View(rivers)
data(airmiles)  # Listed as "ts" for "time-series"
airmiles
str(airmiles)
# Now a dataset that has rows and columns
?anscombe
data(anscombe)  # Appears under "Data" in the Workspace
# See its structure
str(anscombe)
# See its data (or click on name in Workspace)
anscombe
rivers
hist(rivers)
r <- rivers
r <- data.frame(rivers)
View(r)
boxplot(rivers, horizontal = TRUE)
boxplot.stats(rivers)
rivers.low  <- rivers[rivers < 1210]  # Remove outliers
boxplot(rivers.low, horizontal = TRUE)  # Has new outliers
boxplot.stats(rivers.low)
rivers.low2  <- rivers[rivers < 1055]  # Remove again
boxplot(rivers.low2)  # Still one outlier
rm(list = ls())  # Clean up
# Load Data
require("datasets")
# The areas in thousands of square miles of the
# landmasses which exceed 10,000 square miles.
?islands
islands
hist(islands, breaks = 16)
boxplot(islands)
islands.z <- scale(islands)  # M = 0, SD = 1
View(islands.z)
islands.z
hist(islands.z, breaks = 16)  # Histogram of z-scores
boxplot(islands.z)  # Boxplot of z-scores
mean(islands.z)  # M should equal 0
round(mean(islands.z), 2)  # Round off to see M = 0
islands.z
sd(islands.z)  # SD = 1
attr(islands.z, "scaled:center")  # Show original mean
islands.z <- as.numeric(islands.z)  # Converts from matrix back to numeric
islands.z
Load Data
require("datasets")
# The areas in thousands of square miles of the
# landmasses which exceed 10,000 square miles.
?islands
islands
hist(islands, breaks = 16)
boxplot(islands)
# z-scores
islands.z <- scale(islands)  # M = 0, SD = 1
islands.z  # Makes m
View(islands.z)
islands.z <- as.numeric(islands.z)  # Converts from matrix back to numeric
islands.z
islands.ln <- log(islands)  # Natural log (base = e)
hist(islands.ln)
boxplot(islands.ln)
islands.rank1 <- rank(islands)
hist(islands.rank1)
boxplot(islands.rank1)
islands.rank2 <- rank(islands, ties.method = "random")
hist(islands.rank2)
boxplot(islands.rank2)
continent <- ifelse(islands > 1000, 1, 0)
continent
rn1 <- rnorm(1000000)
hist(rn1)
summary(rn1)
# Create variable rn2 with 1 million random normal values
rn2 <- rnorm(1000000)
hist(rn2)
summary(rn2)
# Average scores across two variables
rn.mean <- (rn1 + rn2)/2
hist(rn.mean)
# Multiply scores across two variables
rn.prod <- rn1 * rn2
hist(rn.prod)
summary(rn.prod)
# Kurtosis comparisons
# The package "moments" gives kurtosis where a
# mesokurtic, normal distribution has a value of 3.
# The package "psych" recenters the kurtosis values
# around 0, which is more common now.
install.packages("psych")
help(package = "psych")
install.packages("psych")
require("psych")
kurtosi(rn1)
kurtosi(rn2)
kurtosi(rn.mean)
kurtosi(rn.prod)  # Similar to Cauchy distribution
rm(list = ls())
# R Statistics Essential Training
# Ex04_04
# Coding missing data
# NA = "Not Available"
# Makes certain calculations impossible
x1 <- c(1, 2, 3, NA, 5)
summary(x1)  # Works with NA
mean(x1)  # Doesn't work
# To find missing values
which(is.na(x1))  # Give index number
# Ignore missing values with na.rm = T
mean(x1, na.rm = T)
mean(x1, na.rm = T)
x2 <- x1
x2[is.na(x2)] <- 0
x2
x3 <- ifelse(is.na(x1), 0, x1)
x3
# Square data
x2 <- x^2
hist(x2)
boxplot(x2)
# 4th power
x4 <- x^4
hist(x4)
boxplot(x4)
rm(list = ls())  # Clean up
#################################
#################################
#################################
# R Statistics Essential Training
# Ex05_01
# Selecting cases
# Load data
?mtcars
data(mtcars)
mtcars
mean(mtcars$qsec)
mean(mtcars$qsec[mtcars$cyl == 8])
median(mtcars$hp)
mean(mtcars$mpg[mtcars$hp > median(mtcars$hp)])
cyl.8 <- mtcars[mtcars$cyl == 8, ]
View(cyl.8)
mtcars[mtcars$cyl == 8 & mtcars$carb >= 4, ]
rm(list = ls())  # Clean up
# Load data
?iris
data(iris)
iris
View(iris)
# Load data
?mtcars
data(mtcars)
mtcars
mean(mtcars$qsec)
mean(mtcars$cyl)
library(plyr)
require(plyr)
ddply(yourData, c("block", "date"), summarize, outVal = mean(data))
View(mtcars)
?plyr
ddply(mtcars, "cyl", summarize, outVal = mean(data))
ddply(mtcars, "cyl", summarize, outVal = mean(mtcars))
ddply(mtcars, "cyl", summarize, outVal = mean(mtcars$qsec))
ddply(mtcars, mtcars$qsec, summarize, outVal = mean(mtcars$cyl))
# Load data
?mtcars
data(mtcars)
mtcars
# Mean quarter-mile time (for all cars)
mean(mtcars$qsec)
mean(mtcars$cyl)
mean(mtcars$qsec[mtcars$cyl == 8])
mean(mtcars$qsec[mtcars$cyl())
mean(mtcars$qsec[mtcars$cyl])
mean(mtcars$qsec[mtcars$cyl])
# Load data
?iris
data(iris)
iris
mean(iris$Petal.Width)
View(iris)
aggregate(iris$Petal.Width ~ iris$Species, FUN = mean)
?aggregate
aggregate(iris$Petal.Width, iris$Species, FUN = mean)
by1 <- iris$Species
by1
aggregate(iris$Petal.Width, by1, FUN = mean)
?list
# Split the data file and repeat analyses
# with "aggregate"
# Compare groups on mean of one variable
aggregate(iris$Petal.Width ~ iris$Species, FUN = mean)
# Compare groups on several variables
# Use cbind to list outcome variables
aggregate(cbind(iris$Petal.Width, iris$Petal.Length) ~ iris$Species, FUN = mean)
rm(list = ls())  # Clean up
#################################
#################################
#################################
# R Statistics Essential Training
# Ex05_03
# Merging files
# Load data
?longley
data(longley)
View(longley)
# Split up longley
a1 <- longley[1:14, 1:6]  # Starting data
a2 <- longley[1:14, 6:7]  # New column to add (with "Year" to match)
View(a1)
View(a2)
b <- longley[15:16, ]     # New rows to add
write.table(a2, "~/Desktop/R/longley.a2.txt", sep="\t")
View(b)
write.table(a1, "~/Desktop/R/longley.a1.txt", sep="\t")
write.table(a2, "~/Desktop/R/longley.a2.txt", sep="\t")
write.table(b, "~/Desktop/R/longley.b.txt", sep="\t")
rm(list=ls()) # Clear out everything to start fresh
# Import data
a1t <- read.table("~/Desktop/R/longley.a1.txt", sep="\t")
a2t <- read.table("~/Desktop/R/longley.a2.txt", sep="\t")
View(a1t)
View(a2t)
a.1.2 <- merge(a1t, a2t, by = "Year")  # Merge two data frames
View(a.1.2)
a.1.2  # Check results
b <- read.table("~/Desktop/R/longley.b.txt", sep="\t")
all.data <- rbind(a.1.2, b)  # "Row Bind"
View(all.data)
all.data  # Check data
row.names(all.data) <- NULL  # Reset row names
View(all.data)
# Load data
?ToothGrowth
aggregate(ToothGrowth$len ~ ToothGrowth$supp, FUN = mean)
aggregate(ToothGrowth$len ~ ToothGrowth$supp, FUN = median)
# Load WDI and tidyr package
library(WDI)
library(tidyr)
# Gather fertilizer consumption data from WDI
FertConsumpData <- WDI(indicator = "AG.CON.FERT.ZS")
install.packages("WDI")
install.packages("tidyr")
# Load WDI and tidyr package
library(WDI)
library(tidyr)
FertConsumpData <- WDI(indicator = "AG.CON.FERT.ZS")
View(FertConsumpData)
####Cargar los paquetes que necesitamos para limpiar los datos
library(WDI)
library(countrycode)
library(xlsx)
library(repmis)
library(tidyr)
library(WDI)
library(XML)
library(plyr)
install.packages("XML")
install.packages("plyr")
possible_dir <- c('/Users/alvarolopezguiresse/GoogleDrive/[] ADMINISTRACION PUBLICA/THESIS/Thesis', '/Users/mariorodriguez/Desktop/Thesis')
repmis::set_valid_wd(possible_dir)
possible_dir <- c('/Users/alvarolopezguiresse/GoogleDrive/[] ADMINISTRACION PUBLICA/THESIS/Thesis', '/Users/mariorodriguez/Desktop/Thesis')
repmis::set_valid_wd(possible_dir)
possible_dir <- c('/Users/alvarolopezguiresse/GoogleDrive/[] ADMINISTRACION PUBLICA/tesis/Thesis', '/Users/mariorodriguez/Desktop/Thesis')
repmis::set_valid_wd(possible_dir)
install.packages("plm")
